computeAverage2 <- function () {
for(i in 1:1000) {
tapply(DT$pwgtp15,DT$SEX,mean)
}
}
computeAverage3 <- function () {
for(i in 1:1000) {
DT[,mean(pwgtp15),by=SEX]
}
}
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
system.time( computeAverage1() )
system.time( computeAverage3() )
system.time( computeAverage1() )
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv";
source('~/temp/coursera/getting_cleaning_data/week1/exercise1.r')
data = read.table( dataFile, sep=",", header=TRUE );
head( data );
subset(data,VAL=17)
nrow( subset(data,VAL=17) )
nrow( subset(data,VAL=16) )
nrow( data )
nrow( subset(data,VAL==16) )
nrow( subset(data,VAL==17) )
nrow( subset(data,VAL==1) )
nrow( subset(data,VAL<=24) )
nrow( subset(data,VAdL<=24) )
nrow( subset(data,VAL>=24) )
pdf("xh.pdf")  # set graphical output file
hist(rnorm(100))  # generate 100 N(0,1) variates and plot their histogram
dev.off()  # close the graphical output file
pdf("xh.pdf")  # set graphical output file
hist(rnorm(100))  # generate 100 N(0,1) variates and plot their histogram
dev.off()  # close the graphical output file
hist(rnorm(100))  # generate 100 N(0,1) variates and plot their histogram
hist(rnorm(100))  # generate 100 N(0,1) variates and plot their histogram
hist(rnorm(100))  # generate 100 N(0,1) variates and plot their histogram
hist(rnorm(10000))  # generate 100 N(0,1) variates and plot their histogram
hist(rnorm(1000000))  # generate 100 N(0,1) variates and plot their histogram
hist(data)  # generate 100 N(0,1) variates and plot their histogram
hist(data['VAL'])  # generate 100 N(0,1) variates and plot their histogram
hist(data[,'VAL'])  # generate 100 N(0,1) variates and plot their histogram
hist(data[1:10,'VAL'])  # generate 100 N(0,1) variates and plot their histogram
hist(data[1:10,'VAL'])  # generate 100 N(0,1) variates and plot their histogram
hist(data[1:11,'VAL'])  # generate 100 N(0,1) variates and plot their histogram
hist(data[,'VAL'])  # generate 100 N(0,1) variates and plot their histogram
# code book url: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv";
dataFile <- "./data/us_properties.csv";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
#list.files("./data");
data = read.table( dataFile, sep=",", header=TRUE );
head( data );
nrow( subset(data,VAL>=24) )
source('~/temp/coursera/getting_cleaning_data/week1/exercise1.r')
# code book url: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx";
dataFile <- "./data/natural_gas.csv";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
#list.files("./data");
data = read.table( dataFile, sep=",", header=TRUE );
dat = subset( 18:23, 7:15 );
#nrow( subset(data,VAL>=24) )
dat = subset( data, 18:23, 7:15 );
dat = data[ 18:23, 7:15 ];
dat
sum(dat$Zip*dat$Ext,na.rm=T)
dat = data[ 18:23, 7:15 ];
sum(dat$Zip*dat$Ext,na.rm=T)
getwd();
getwd(".");
setwd(".");
getwd();
setwd("~/temp/coursera/getting_cleaning_data/week1")
# code book url: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
getwd();
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx";
dataFile <- "./data/natural_gas.csv";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
#list.files("./data");
data = read.table( dataFile, sep=",", header=TRUE );
dat = data[ 18:23, 7:15 ];
sum(dat$Zip*dat$Ext,na.rm=T)
#nrow( subset(data,VAL>=24) )
# code book url: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
getwd();
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx";
dataFile <- "./data/natural_gas.xlsx";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
#list.files("./data");
data = read.table( dataFile, sep=",", header=TRUE );
dat = data[ 18:23, 7:15 ];
sum(dat$Zip*dat$Ext,na.rm=T)
#nrow( subset(data,VAL>=24) )
dat = data[ 18:23,  ];
dat
data = read.xlsx( dataFile, sheetIndex=1, header=TRUE );
data = read.xls( dataFile, sheetIndex=1, header=TRUE );
install.packages(xlsx)
install.packages("xlsx")
# install.packages("xlsx")
library(xlsx);
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx";
dataFile <- "./data/natural_gas.xlsx";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
#list.files("./data");
data = read.xls( dataFile, sheetIndex=1, header=TRUE );
dat = data[ 18:23,  ];
dat
sum(dat$Zip*dat$Ext,na.rm=T)
#nrow( subset(data,VAL>=24) )
dat = data[ 18:23, 7:15 ];
dat
dataFile
data = read.xls( dataFile, sheetIndex=1, header=TRUE );
data = read.xlsx( dataFile, sheetIndex=1, header=TRUE );
dat = data[ 18:23, 7:15 ];
dat
data = read.xlsx( dataFile, sheetIndex=1 );
dat = data[ 18:23, 7:15 ];
dat
sum(dat$Zip*dat$Ext,na.rm=T)
dat = data[ 18:23,  ];
dat
dat = data[ 18:23, 7:15 ];
dat
data = read.xlsx( dataFile, sheetIndex=1, header=TRUE, startRow=18, endRow=23, startCol=7, endRow=15 );
data = read.xlsx( dataFile, sheetIndex=1, header=TRUE, startRow=18, endRow=23, startCol=7, endCol=15 );
dat = read.xlsx( dataFile, sheetIndex=1, header=TRUE, startRow=18, endRow=23, startCol=7, endCol=15 );
dat
sum(dat$Zip*dat$Ext,na.rm=T)
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml";
dataFile <- "./data/baltimore_restaurants";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
library(XML)
install.packages("XML")
install.packages("XML")
library(XML)
doc = read.xlsx( dataFile, sheetIndex=1, header=TRUE, startRow=18, endRow=23, startCol=7, endCol=15 );
doc <- xmlTreeParse( dataUrl )
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml";
doc <- xmlTreeParse( dataUrl )
dataUrl <- "./data/baltimore_restaurants.xml";
#https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
doc <- xmlTreeParse( dataUrl )
rootNode = xmlRoot(doc)
xPathSApply( rootNode, "//zipcode", xmlValue)
xpathSApply( rootNode, "//zipcode", xmlValue)
xpathSApply( rootNode, "/zipcode", xmlValue)
xpathSApply( rootNode, "//zipcode", xmlValue)
xpathSApply( rootNode, "//zipcode" )
xpathSApply( rootNode, "//zipcode", value)
doc <- xmlTreeParse( dataUrl, useInternal=TRUE )
# read a specific region of the excel file
rootNode = xmlRoot(doc)
xpathSApply( rootNode, "//zipcode", xmlValue)
#install.packages("XML")
library(XML)
#https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
# I downloaded the file manually. otherwise it doesn't recognize it as xml, i don't know why...
dataUrl <- "./data/baltimore_restaurants.xml";
doc <- xmlTreeParse( dataUrl, useInternal=TRUE )
# read a specific region of the excel file
# get the root node
rootNode = xmlRoot(doc)
# find those mathing our needs
xpathSApply( rootNode, "//row", xmlValue)
results <- xpathSApply( rootNode, "//row", xmlValue)
length( results )
results <- xpathSApply( rootNode, "//row/row", xmlValue)
length( results )
xpathSApply( rootNode, "//row/row", xmlValue)
results <- xpathSApply( rootNode, "//row/row[@zipcode==21231]", xmlValue)
results <- xpathSApply( rootNode, "//row/row[@zipcode=21231]", xmlValue)
length( results )
results <- xpathSApply( rootNode, "//row[@zipcode=21231]", xmlValue)
length( results )
results <- xpathSApply( rootNode, "//row[@zipcode='21231']", xmlValue)
length( results )
results <- xpathSApply( rootNode, "//row[zipcode='21231']", xmlValue)
length( results )
results
require(data.table)
# Set source url and load it
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
dataFile <- './q5_dataset.csv'
# Just download if it has not been so yet
if( !file.exists(dataFile) ){
download.file(dataUrl, dataFile, method="curl")
}
# read the dataset
DT <- fread( dataFile)
computeAverage1 <- function () {
for(i in 1:1000) {
sapply(split(DT$pwgtp15,DT$SEX),mean)
}
}
computeAverage2 <- function () {
for(i in 1:1000) {
tapply(DT$pwgtp15,DT$SEX,mean)
}
}
computeAverage3 <- function () {
for(i in 1:1000) {
DT[,mean(pwgtp15),by=SEX]
}
}
####
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
system.time( computeAverage1() )
system.time( computeAverage2() )
system.time( computeAverage3() )
install.packages("RMySQL")
db <- dbConnect( MySQL(), user=“genome”,
host=“genome-mysql.cse.ucsc.edu”);
db <- dbConnect( MySQL(), user="genome",
host="genome-mysql.cse.ucsc.edu");
install.packages("RMySQL")
db <- dbConnect( MySQL(), user="genome",
host="genome-mysql.cse.ucsc.edu");
library(RMySQL)
db <- dbConnect( MySQL(), user="genome",
host="genome-mysql.cse.ucsc.edu");
result <- dgGetQuery( db, “show databases;”); dbDisconnect(db);
result <- dgGetQuery( db, "show databases;"); dbDisconnect(db);
result <- dgGetQuery( db, "show databases;");
result <- dbGetQuery( db, "show databases;");
dbDisconnect(db);
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
allTables <- dbListTables(db)
dbDisconnect(db);
length(allTables)
allTables[1:5]
dbListFileds( hg19, "affyU133Plus2")
dbListFields( hg19, "affyU133Plus2")
SQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
allTables <- dbListTables(db)
length(allTables)
dbListFields( hg19, "affyU133Plus2")
dbDisconnect(db);
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
allTables <- dbListTables(db)
length(allTables)
dbListFields( hg19, "affyU133Plus2")
dbDisconnect(db);
dbListFields( db, "affyU133Plus2")
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
allTables <- dbListTables(db)
length(allTables)
dbListFields( db, "affyU133Plus2")
dbDisconnect(db);
# ---
# connect to specific db
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
# get all tables
allTables <- dbListTables(db)
length(allTables)
# list fields in table affyU133Plus2
dbListFields( db, "affyU133Plus2")
# perform a query
result <- dbGetQuery( db, "select count(*) from affyU133Plus2;");
result <- dbReadTable( db, "affyU133Plus2" )
head( result )
# diconnect from server
dbDisconnect(db);
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
# get all tables
allTables <- dbListTables(db)
length(allTables)
# list fields in table affyU133Plus2
dbListFields( db, "affyU133Plus2")
# perform a query
result <- dbGetQuery( db, "select count(*) from affyU133Plus2;");
# get whole table (commented out to avoid downloading a big thing)
# result <- dbReadTable( db, "affyU133Plus2" )
# head( result )
# query
query <- dbGetQuery( db, "SELECT * from affyU133Plus2 where mismathes between 1 and 3");
result <- fetch( query );
quantile( result$misMatches )
# diconnect from server
dbDisconnect(db);
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
# get all tables
allTables <- dbListTables(db)
length(allTables)
# list fields in table affyU133Plus2
dbListFields( db, "affyU133Plus2")
# perform a query
#result <- dbGetQuery( db, "select count(*) from affyU133Plus2;");
# get whole table (commented out to avoid downloading a big thing)
# result <- dbReadTable( db, "affyU133Plus2" )
# head( result )
# query
query <- dbGetQuery( db, "SELECT * from affyU133Plus2 where mismathes between 1 and 3");
result <- fetch( query );
quantile( result$misMatches )
query <- dbGetQuery( db, "SELECT * from affyU133Plus2 where miMatches between 1 and 3");
query <- dbGetQuery( db, "SELECT * from affyU133Plus2 where misMatches between 1 and 3");
warnings()
result <- fetch( query );
query <- dbGetQuery( db, "SELECT * from affyU133Plus2 where misMatches between 1 and 3");
result <- fetch( query );
quantile( result$misMatches )
dbClearResult(query)
query <- dbSendQuery( db, "SELECT * from affyU133Plus2 where misMatches between 1 and 3");
result <- fetch( query );
quantile( result$misMatches )
dbClearResult(query)
# diconnect from server
dbDisconnect(db);
db <- dbConnect( MySQL(), user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu");
# get all tables
allTables <- dbListTables(db)
length(allTables)
# list fields in table affyU133Plus2
dbListFields( db, "affyU133Plus2")
# perform a query
#result <- dbGetQuery( db, "select count(*) from affyU133Plus2;");
# get whole table (commented out to avoid downloading a big thing)
# result <- dbReadTable( db, "affyU133Plus2" )
# head( result )
# query (note this time we use dbSendQuery instead of dbGetQuery)
#query <- dbSendQuery( db, "SELECT * from affyU133Plus2 where misMatches between 1 and 3");
result <- dbGetQuery( db, "SELECT * from affyU133Plus2 where misMatches between 1 and 3");
quantile( result$misMatches )
# diconnect from server
dbDisconnect(db);
ds <- url("https://api.github.com/users/jtleek/repos")
ds
library(jsonlite)
ds <- fromJSON("https://api.github.com/users/jtleek/repos")
names(ds)
s <- subset( ds, name=="datasharing")
s
s$created_at
acs <- read.csv( "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", headers=TRUE, sep=",")
acs <- read.csv( "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", header=TRUE, sep=",")
acs <- read.csv( "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", header=TRUE, sep=",")
library("sqldf")
install.package( "sqldf")
packages.install( "sqldf")
install.packages( "sqldf")
library("sqldf")
library("sqldf")
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv";
dataFile <- "./data/american_survey";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
# donwload the dataset and convert it to a data frame
acs = read.table( dataFile, sep=",", header=TRUE );
sqldf("select * from acs where AGEP < 50 and pwgtp1")
acs <- read.table( dataFile, sep=",", header=TRUE );
sqldf("select * from acs where AGEP < 50 and pwgtp1")
acs
sqldf("select * from acs")
library(RMySQL)
library(sqldf)
acs <- read.table( dataFile, sep=",", header=TRUE );
sqldf("select * from acs")
options(sqldf.driver = "MySQL")
sqldf("select * from acs")
library(sqldf)
library(RMySQL)
options(sqldf.driver = "MySQL")
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv";
dataFile <- "./data/american_survey";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
# donwload the dataset and convert it to a data frame
acs <- read.table( dataFile, sep=",", header=TRUE );
sqldf("select * from acs")
options(sqldf.driver = "SQLite") # as per FAQ #7 force SQLite
options(gsubfn.engine = "R") # as per FAQ #5 use R code rather than tcltk
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv";
dataFile <- "./data/american_survey";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
# donwload the dataset and convert it to a data frame
acs <- read.table( dataFile, sep=",", header=TRUE );
sqldf("select * from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select unique AGEP from acs")
unique(acs$AGEP)
??read.lines
fileUrl <- "http://biostat.jhsph.edu/~jleek/contact.html"
lines <- readLines( fileUrl )
lines
lines[10]
nchar( lines[10] )
nchar( lines[100] )
nchar( lines[10] )
nchar( lines[20] )
nchar( lines[30] )
nchar( lines[100] )
nchar( lines[10] )
nchar( lines[20] )
nchar( lines[30] )
nchar( lines[100] )
dataUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for";
dataFile <- "./data/fwf.for";
# make sure the data direcory exists
if( !file.exists("./data") ){
dir.create("data");
}
# Set the Working directory to "data"
# setwd("./data");
# download the data file
if( !file.exists( dataFile ) ){
download.file( dataUrl, destfile=dataFile, method="curl");
}
ds <- read.fwf( file=dataFile, widths=c( -1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4 ), skip=4 )
sum( ds[,4] )
